import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats, signal
from scipy.fft import fft, fftfreq
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.stats.diagnostic import acorr_ljungbox
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import warnings
import japanize_matplotlib

warnings.filterwarnings('ignore')

class AdvancedFactoryDataInsights:
    """å·¥å ´ãƒ‡ãƒ¼ã‚¿ã®é«˜åº¦ãªæ´å¯Ÿåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, data, datetime_col=None):
        """
        åˆæœŸåŒ–
        
        Args:
            data (pd.DataFrame): åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿
            datetime_col (str): æ—¥æ™‚åˆ—åï¼ˆè‡ªå‹•æ¤œå‡ºã‚‚å¯èƒ½ï¼‰
        """
        self.data = data.copy()
        self.datetime_col = datetime_col
        self.insights = []
        
        if self.datetime_col is None:
            self._auto_detect_datetime_col()
        
        # æ•°å€¤åˆ—ã¨ã‚«ãƒ†ã‚´ãƒªåˆ—ã®è­˜åˆ¥
        self.numeric_cols = self.data.select_dtypes(include=[np.number]).columns.tolist()
        self.categorical_cols = self.data.select_dtypes(include=['object']).columns.tolist()
        
        print(f"é«˜åº¦åˆ†ææº–å‚™å®Œäº†: {len(self.numeric_cols)}å€‹ã®æ•°å€¤åˆ—, {len(self.categorical_cols)}å€‹ã®ã‚«ãƒ†ã‚´ãƒªåˆ—")
    
    def _auto_detect_datetime_col(self):
        """æ—¥æ™‚åˆ—ã®è‡ªå‹•æ¤œå‡º"""
        datetime_cols = self.data.select_dtypes(include=['datetime64']).columns
        if len(datetime_cols) > 0:
            self.datetime_col = datetime_cols[0]
            print(f"æ—¥æ™‚åˆ—ã¨ã—ã¦ {self.datetime_col} ã‚’ä½¿ç”¨ã—ã¾ã™")
        else:
            print("æ—¥æ™‚åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä¸€éƒ¨ã®æ™‚ç³»åˆ—åˆ†æã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
    
    def operational_pattern_analysis(self):
        """ç¨¼åƒãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        print("\n" + "=" * 60)
        print("ã€ç¨¼åƒãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã€‘")
        print("=" * 60)
        
        if self.datetime_col is None:
            print("æ—¥æ™‚åˆ—ãŒãªã„ãŸã‚ã€ç¨¼åƒãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return
        
        # æ™‚é–“åˆ¥ã®ç‰¹å¾´
        df_time = self.data.copy()
        df_time['hour'] = df_time[self.datetime_col].dt.hour
        df_time['day_of_week'] = df_time[self.datetime_col].dt.dayofweek
        df_time['day_of_month'] = df_time[self.datetime_col].dt.day
        df_time['month'] = df_time[self.datetime_col].dt.month
        
        # ä»£è¡¨çš„ãªæ•°å€¤åˆ—ã‚’é¸æŠ
        target_cols = self.numeric_cols[:3] if len(self.numeric_cols) >= 3 else self.numeric_cols
        
        if len(target_cols) == 0:
            print("åˆ†æå¯¾è±¡ã®æ•°å€¤åˆ—ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # æ™‚é–“åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³
        hourly_stats = df_time.groupby('hour')[target_cols].mean()
        hourly_stats.plot(ax=axes[0,0], marker='o')
        axes[0,0].set_title('æ™‚é–“åˆ¥å¹³å‡å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³')
        axes[0,0].set_xlabel('æ™‚é–“')
        axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        
        # æ›œæ—¥åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³
        daily_stats = df_time.groupby('day_of_week')[target_cols].mean()
        daily_stats.plot(kind='bar', ax=axes[0,1])
        axes[0,1].set_title('æ›œæ—¥åˆ¥å¹³å‡å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³')
        axes[0,1].set_xlabel('æ›œæ—¥ (0=æœˆæ›œ)')
        axes[0,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        
        # æœˆåˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³
        monthly_stats = df_time.groupby('month')[target_cols].mean()
        monthly_stats.plot(ax=axes[1,0], marker='o')
        axes[1,0].set_title('æœˆåˆ¥å¹³å‡å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³')
        axes[1,0].set_xlabel('æœˆ')
        axes[1,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        
        # ãƒ‡ãƒ¼ã‚¿å¯†åº¦ï¼ˆç¨¼åƒç‡ï¼‰
        hourly_counts = df_time.groupby('hour').size()
        hourly_counts.plot(kind='bar', ax=axes[1,1], color='orange')
        axes[1,1].set_title('æ™‚é–“åˆ¥ãƒ‡ãƒ¼ã‚¿æ•°ï¼ˆç¨¼åƒå¯†åº¦ï¼‰')
        axes[1,1].set_xlabel('æ™‚é–“')
        axes[1,1].set_ylabel('ãƒ‡ãƒ¼ã‚¿æ•°')
        
        plt.tight_layout()
        plt.show()
        
        # ç¨¼åƒãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å¾´ã‚’è¨˜éŒ²
        peak_hour = hourly_counts.idxmax()
        min_hour = hourly_counts.idxmin()
        self.insights.append(f"ãƒ”ãƒ¼ã‚¯ç¨¼åƒæ™‚é–“: {peak_hour}æ™‚")
        self.insights.append(f"æœ€ä½ç¨¼åƒæ™‚é–“: {min_hour}æ™‚")
        
        # é€±æœ«ã®ç¨¼åƒçŠ¶æ³
        weekend_ratio = df_time[df_time['day_of_week'].isin([5, 6])].shape[0] / len(df_time)
        if weekend_ratio < 0.1:
            self.insights.append("é€±æœ«ã®ç¨¼åƒã¯é™å®šçš„ï¼ˆå¹³æ—¥ä¸­å¿ƒã®é‹è»¢ï¼‰")
        
        return df_time
    
    def periodicity_detection(self):
        """å‘¨æœŸæ€§ã®æ¤œå‡º"""
        print("\n" + "=" * 60)
        print("ã€å‘¨æœŸæ€§æ¤œå‡ºã€‘")
        print("=" * 60)
        
        if len(self.numeric_cols) == 0:
            print("æ•°å€¤åˆ—ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # ä»£è¡¨çš„ãªåˆ—ã‚’é¸æŠ
        target_cols = self.numeric_cols[:4]
        
        fig, axes = plt.subplots(len(target_cols), 2, figsize=(15, 4*len(target_cols)))
        if len(target_cols) == 1:
            axes = axes.reshape(1, -1)
        
        for i, col in enumerate(target_cols):
            data_col = self.data[col].dropna()
            
            if len(data_col) < 50:  # ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                continue
            
            # è‡ªå·±ç›¸é–¢
            autocorr = [data_col.autocorr(lag=lag) for lag in range(1, min(100, len(data_col)//2))]
            axes[i,0].plot(autocorr)
            axes[i,0].set_title(f'{col} - è‡ªå·±ç›¸é–¢')
            axes[i,0].set_xlabel('ãƒ©ã‚°')
            axes[i,0].set_ylabel('è‡ªå·±ç›¸é–¢ä¿‚æ•°')
            axes[i,0].axhline(y=0, color='k', linestyle='--', alpha=0.5)
            
            # ä¸»è¦ãªå‘¨æœŸã®æ¤œå‡º
            significant_lags = [lag+1 for lag, corr in enumerate(autocorr) if abs(corr) > 0.3]
            if significant_lags:
                self.insights.append(f"{col}: ä¸»è¦å‘¨æœŸå€™è£œ = {significant_lags[:3]}ãƒã‚¤ãƒ³ãƒˆ")
            
            # FFT ã«ã‚ˆã‚‹å‘¨æ³¢æ•°åˆ†æ
            if len(data_col) >= 100:
                # ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
                normalized_data = (data_col - data_col.mean()) / data_col.std()
                
                # FFTè¨ˆç®—
                fft_vals = fft(normalized_data.values)
                freqs = fftfreq(len(normalized_data))
                
                # ãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«
                power = np.abs(fft_vals)**2
                
                # æ­£ã®å‘¨æ³¢æ•°ã®ã¿ãƒ—ãƒ­ãƒƒãƒˆ
                pos_mask = freqs > 0
                axes[i,1].plot(freqs[pos_mask], power[pos_mask])
                axes[i,1].set_title(f'{col} - ãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«')
                axes[i,1].set_xlabel('å‘¨æ³¢æ•°')
                axes[i,1].set_ylabel('ãƒ‘ãƒ¯ãƒ¼')
                
                # ä¸»è¦ãªå‘¨æ³¢æ•°æˆåˆ†ã‚’ç‰¹å®š
                top_freq_indices = np.argsort(power[pos_mask])[-3:][::-1]
                top_freqs = freqs[pos_mask][top_freq_indices]
                top_periods = [1/f if f > 0 else np.inf for f in top_freqs]
                
                significant_periods = [p for p in top_periods if 2 <= p <= len(data_col)/4]
                if significant_periods:
                    self.insights.append(f"{col}: FFTä¸»è¦å‘¨æœŸ = {[round(p, 1) for p in significant_periods[:2]]}")
        
        plt.tight_layout()
        plt.show()
    
    def seasonal_decomposition_analysis(self):
        """å­£ç¯€åˆ†è§£åˆ†æ"""
        print("\n" + "=" * 60)
        print("ã€å­£ç¯€åˆ†è§£åˆ†æã€‘")
        print("=" * 60)
        
        if self.datetime_col is None or len(self.numeric_cols) == 0:
            print("æ—¥æ™‚åˆ—ã¾ãŸã¯æ•°å€¤åˆ—ãŒãªã„ãŸã‚ã€å­£ç¯€åˆ†è§£åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return
        
        # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        ts_data = self.data.set_index(self.datetime_col)
        
        # ä»£è¡¨çš„ãªåˆ—ã‚’é¸æŠ
        target_cols = self.numeric_cols[:2]
        
        for col in target_cols:
            try:
                # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆæ¬ æå€¤è£œé–“ï¼‰
                series = ts_data[col].fillna(method='ffill').fillna(method='bfill')
                
                # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ç‚¹ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if len(series) < 20:
                    print(f"{col}: ãƒ‡ãƒ¼ã‚¿ç‚¹ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                    continue
                
                # é©åˆ‡ãªå‘¨æœŸã‚’æ¨å®š
                data_span_days = (series.index.max() - series.index.min()).days
                if data_span_days >= 14:
                    period = min(7, len(series) // 4)  # é€±å‘¨æœŸã¾ãŸã¯é©å¿œçš„
                else:
                    period = max(2, len(series) // 10)
                
                # å­£ç¯€åˆ†è§£
                if len(series) >= 2 * period:
                    decomp = seasonal_decompose(series, model='additive', period=period, extrapolate_trend='freq')
                    
                    # å¯è¦–åŒ–
                    fig, axes = plt.subplots(4, 1, figsize=(15, 12))
                    
                    decomp.observed.plot(ax=axes[0], title=f'{col} - è¦³æ¸¬å€¤')
                    decomp.trend.plot(ax=axes[1], title='ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†')
                    decomp.seasonal.plot(ax=axes[2], title='å­£ç¯€æˆåˆ†')
                    decomp.resid.plot(ax=axes[3], title='æ®‹å·®æˆåˆ†')
                    
                    plt.tight_layout()
                    plt.show()
                    
                    # æˆåˆ†ã®é‡è¦æ€§è©•ä¾¡
                    trend_var = decomp.trend.var()
                    seasonal_var = decomp.seasonal.var()
                    resid_var = decomp.resid.var()
                    
                    total_var = trend_var + seasonal_var + resid_var
                    
                    if seasonal_var / total_var > 0.1:
                        self.insights.append(f"{col}: æ˜ç¢ºãªå­£ç¯€æ€§ (å¯„ä¸ç‡{seasonal_var/total_var:.1%})")
                    
                    if trend_var / total_var > 0.3:
                        self.insights.append(f"{col}: å¼·ã„ãƒˆãƒ¬ãƒ³ãƒ‰ (å¯„ä¸ç‡{trend_var/total_var:.1%})")
                        
            except Exception as e:
                print(f"{col}ã®å­£ç¯€åˆ†è§£ã§ã‚¨ãƒ©ãƒ¼: {e}")
    
    def change_point_detection(self):
        """å¤‰åŒ–ç‚¹æ¤œå‡º"""
        print("\n" + "=" * 60)
        print("ã€å¤‰åŒ–ç‚¹æ¤œå‡ºã€‘")
        print("=" * 60)
        
        if len(self.numeric_cols) == 0:
            print("æ•°å€¤åˆ—ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        target_cols = self.numeric_cols[:3]
        
        for col in target_cols:
            data_col = self.data[col].dropna()
            
            if len(data_col) < 20:
                continue
            
            # ç§»å‹•å¹³å‡ã¨ç§»å‹•æ¨™æº–åå·®
            window = min(10, len(data_col) // 5)
            rolling_mean = data_col.rolling(window=window).mean()
            rolling_std = data_col.rolling(window=window).std()
            
            # çµ±è¨ˆçš„å¤‰åŒ–ç‚¹ã®æ¤œå‡ºï¼ˆç°¡å˜ãªæ‰‹æ³•ï¼‰
            mean_changes = rolling_mean.diff().abs()
            std_changes = rolling_std.diff().abs()
            
            # é–¾å€¤ã‚’è¶…ãˆã‚‹å¤‰åŒ–ç‚¹
            mean_threshold = mean_changes.quantile(0.95)
            std_threshold = std_changes.quantile(0.95)
            
            mean_change_points = mean_changes[mean_changes > mean_threshold].index
            std_change_points = std_changes[std_changes > std_threshold].index
            
            # å¯è¦–åŒ–
            fig, axes = plt.subplots(3, 1, figsize=(15, 10))
            
            # å…ƒãƒ‡ãƒ¼ã‚¿ã¨ç§»å‹•å¹³å‡
            axes[0].plot(data_col.index, data_col.values, alpha=0.7, label='åŸãƒ‡ãƒ¼ã‚¿')
            axes[0].plot(rolling_mean.index, rolling_mean.values, color='red', linewidth=2, label='ç§»å‹•å¹³å‡')
            
            # å¤‰åŒ–ç‚¹ã‚’ãƒãƒ¼ã‚¯
            for cp in mean_change_points:
                axes[0].axvline(x=cp, color='red', linestyle='--', alpha=0.7)
            
            axes[0].set_title(f'{col} - ãƒ‡ãƒ¼ã‚¿ã¨ç§»å‹•å¹³å‡')
            axes[0].legend()
            
            # å¹³å‡ã®å¤‰åŒ–é‡
            axes[1].plot(mean_changes.index, mean_changes.values)
            axes[1].axhline(y=mean_threshold, color='red', linestyle='--', label=f'é–¾å€¤({mean_threshold:.3f})')
            axes[1].set_title('å¹³å‡å€¤ã®å¤‰åŒ–é‡')
            axes[1].legend()
            
            # æ¨™æº–åå·®ã®å¤‰åŒ–é‡
            axes[2].plot(std_changes.index, std_changes.values)
            axes[2].axhline(y=std_threshold, color='red', linestyle='--', label=f'é–¾å€¤({std_threshold:.3f})')
            axes[2].set_title('æ¨™æº–åå·®ã®å¤‰åŒ–é‡')
            axes[2].legend()
            
            plt.tight_layout()
            plt.show()
            
            # ç™ºè¦‹äº‹é …ã®è¨˜éŒ²
            if len(mean_change_points) > 0:
                self.insights.append(f"{col}: {len(mean_change_points)}å€‹ã®å¹³å‡å€¤å¤‰åŒ–ç‚¹ã‚’æ¤œå‡º")
            
            if len(std_change_points) > 0:
                self.insights.append(f"{col}: {len(std_change_points)}å€‹ã®åˆ†æ•£å¤‰åŒ–ç‚¹ã‚’æ¤œå‡º")
    
    def cross_correlation_analysis(self):
        """ã‚¯ãƒ­ã‚¹ç›¸é–¢åˆ†æ"""
        print("\n" + "=" * 60)
        print("ã€ã‚¯ãƒ­ã‚¹ç›¸é–¢åˆ†æã€‘")
        print("=" * 60)
        
        if len(self.numeric_cols) < 2:
            print("ã‚¯ãƒ­ã‚¹ç›¸é–¢åˆ†æã«ã¯æœ€ä½2ã¤ã®æ•°å€¤åˆ—ãŒå¿…è¦ã§ã™")
            return
        
        # ä¸»è¦ãªå¤‰æ•°ãƒšã‚¢ã‚’é¸æŠ
        target_cols = self.numeric_cols[:4]
        
        cross_corr_results = {}
        
        for i, col1 in enumerate(target_cols):
            for j, col2 in enumerate(target_cols[i+1:], i+1):
                
                # å…±é€šã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                common_data = self.data[[col1, col2]].dropna()
                
                if len(common_data) < 20:
                    continue
                
                series1 = common_data[col1]
                series2 = common_data[col2]
                
                # ã‚¯ãƒ­ã‚¹ç›¸é–¢ã®è¨ˆç®—
                max_lag = min(20, len(series1) // 4)
                lags = range(-max_lag, max_lag + 1)
                cross_corrs = []
                
                for lag in lags:
                    if lag == 0:
                        corr = series1.corr(series2)
                    elif lag > 0:
                        corr = series1[:-lag].corr(series2[lag:])
                    else:
                        corr = series1[-lag:].corr(series2[:lag])
                    cross_corrs.append(corr)
                
                # æœ€å¤§ç›¸é–¢ã¨ãã®ãƒ©ã‚°ã‚’ç‰¹å®š
                max_corr_idx = np.nanargmax(np.abs(cross_corrs))
                max_corr = cross_corrs[max_corr_idx]
                max_lag = lags[max_corr_idx]
                
                cross_corr_results[f"{col1}-{col2}"] = {
                    'lags': lags,
                    'correlations': cross_corrs,
                    'max_corr': max_corr,
                    'max_lag': max_lag
                }
                
                # æœ‰æ„ãªç›¸é–¢ã®è¨˜éŒ²
                if abs(max_corr) > 0.5:
                    if max_lag == 0:
                        self.insights.append(f"{col1}-{col2}: åŒæ™‚ç›¸é–¢ r={max_corr:.3f}")
                    else:
                        self.insights.append(f"{col1}-{col2}: ãƒ©ã‚°{max_lag}ã§æœ€å¤§ç›¸é–¢ r={max_corr:.3f}")
        
        # å¯è¦–åŒ–
        if cross_corr_results:
            n_pairs = len(cross_corr_results)
            n_cols = min(3, n_pairs)
            n_rows = (n_pairs + n_cols - 1) // n_cols
            
            fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))
            if n_pairs == 1:
                axes = [axes]
            elif n_rows == 1:
                axes = [axes]
            else:
                axes = axes.flatten()
            
            for idx, (pair_name, result) in enumerate(cross_corr_results.items()):
                if idx < len(axes):
                    axes[idx].plot(result['lags'], result['correlations'], 'o-')
                    axes[idx].axhline(y=0, color='k', linestyle='--', alpha=0.5)
                    axes[idx].axvline(x=0, color='k', linestyle='--', alpha=0.5)
                    axes[idx].set_title(f'{pair_name}\næœ€å¤§: r={result["max_corr"]:.3f} (ãƒ©ã‚°{result["max_lag"]})')
                    axes[idx].set_xlabel('ãƒ©ã‚°')
                    axes[idx].set_ylabel('ç›¸é–¢ä¿‚æ•°')
            
            # ä½™ã£ãŸè»¸ã‚’éè¡¨ç¤º
            for idx in range(len(cross_corr_results), len(axes)):
                axes[idx].set_visible(False)
            
            plt.tight_layout()
            plt.show()
        
        return cross_corr_results
    
    def process_state_analysis(self):
        """ãƒ—ãƒ­ã‚»ã‚¹çŠ¶æ…‹åˆ†æ"""
        print("\n" + "=" * 60)
        print("ã€ãƒ—ãƒ­ã‚»ã‚¹çŠ¶æ…‹åˆ†æã€‘")
        print("=" * 60)
        
        if len(self.numeric_cols) < 2:
            print("ãƒ—ãƒ­ã‚»ã‚¹çŠ¶æ…‹åˆ†æã«ã¯è¤‡æ•°ã®æ•°å€¤åˆ—ãŒå¿…è¦ã§ã™")
            return
        
        # ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        scaled_data = scaler.fit_transform(self.data[self.numeric_cols].fillna(0))
        scaled_df = pd.DataFrame(scaled_data, columns=self.numeric_cols, index=self.data.index)
        
        # ä¸»æˆåˆ†åˆ†æ
        from sklearn.decomposition import PCA
        pca = PCA(n_components=min(3, len(self.numeric_cols)))
        pca_result = pca.fit_transform(scaled_data)
        
        # ãƒ—ãƒ­ã‚»ã‚¹çŠ¶æ…‹ã®å¯è¦–åŒ–
        if pca.n_components >= 2:
            fig = plt.figure(figsize=(15, 5))
            
            # PC1 vs PC2
            plt.subplot(1, 3, 1)
            plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.6, s=20)
            plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')
            plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')
            plt.title('ãƒ—ãƒ­ã‚»ã‚¹çŠ¶æ…‹ç©ºé–“ (PC1 vs PC2)')
            
            # æ™‚ç³»åˆ—ã§ã®ä¸»æˆåˆ†å¤‰åŒ–
            if pca.n_components >= 1:
                plt.subplot(1, 3, 2)
                plt.plot(pca_result[:, 0], alpha=0.7)
                plt.title('PC1ã®æ™‚ç³»åˆ—å¤‰åŒ–')
                plt.xlabel('æ™‚é–“')
                plt.ylabel('PC1')
                
            if pca.n_components >= 2:
                plt.subplot(1, 3, 3)
                plt.plot(pca_result[:, 1], alpha=0.7)
                plt.title('PC2ã®æ™‚ç³»åˆ—å¤‰åŒ–')
                plt.xlabel('æ™‚é–“')
                plt.ylabel('PC2')
            
            plt.tight_layout()
            plt.show()
        
        # ç•°å¸¸ãªé‹è»¢çŠ¶æ…‹ã®æ¤œå‡º
        from sklearn.ensemble import IsolationForest
        iso_forest = IsolationForest(contamination=0.05, random_state=42)
        anomaly_scores = iso_forest.fit_predict(scaled_data)
        
        n_anomalies = (anomaly_scores == -1).sum()
        anomaly_rate = n_anomalies / len(self.data) * 100
        
        print(f"ç•°å¸¸é‹è»¢çŠ¶æ…‹: {n_anomalies}ä»¶ ({anomaly_rate:.2f}%)")
        
        if anomaly_rate > 2:
            self.insights.append(f"å¤šæ•°ã®ç•°å¸¸é‹è»¢çŠ¶æ…‹ã‚’æ¤œå‡º ({n_anomalies}ä»¶, {anomaly_rate:.1f}%)")
        
        # ãƒ—ãƒ­ã‚»ã‚¹å®‰å®šæ€§ã®è©•ä¾¡
        pc1_stability = np.std(pca_result[:, 0])
        if pc1_stability > 2:
            self.insights.append("ãƒ—ãƒ­ã‚»ã‚¹ã®ä¸»è¦æˆåˆ†ã«é«˜ã„å¤‰å‹•æ€§")
        
        return pca_result, anomaly_scores
    
    def interactive_exploration_guide(self):
        """å¯¾è©±çš„æ¢ç´¢ã®ã‚¬ã‚¤ãƒ‰"""
        print("\n" + "=" * 60)
        print("ã€å¯¾è©±çš„æ¢ç´¢ã‚¬ã‚¤ãƒ‰ã€‘")
        print("=" * 60)
        
        print("ä»¥ä¸‹ã®é–¢æ•°ã‚’å€‹åˆ¥ã«å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã€è©³ç´°ãªåˆ†æã‚’è¡Œãˆã¾ã™ï¼š\n")
        
        analysis_functions = {
            "1. ç¨¼åƒãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ": "explorer.operational_pattern_analysis()",
            "2. å‘¨æœŸæ€§æ¤œå‡º": "explorer.periodicity_detection()",
            "3. å­£ç¯€åˆ†è§£åˆ†æ": "explorer.seasonal_decomposition_analysis()",
            "4. å¤‰åŒ–ç‚¹æ¤œå‡º": "explorer.change_point_detection()",
            "5. ã‚¯ãƒ­ã‚¹ç›¸é–¢åˆ†æ": "explorer.cross_correlation_analysis()",
            "6. ãƒ—ãƒ­ã‚»ã‚¹çŠ¶æ…‹åˆ†æ": "explorer.process_state_analysis()",
            "7. ã‚«ã‚¹ã‚¿ãƒ å¤‰æ•°åˆ†æ": "explorer.custom_variable_analysis('åˆ—å')",
            "8. ç‰¹å®šæœŸé–“åˆ†æ": "explorer.time_period_analysis('é–‹å§‹æ—¥', 'çµ‚äº†æ—¥')"
        }
        
        for desc, func in analysis_functions.items():
            print(f"{desc}:")
            print(f"   {func}")
            print()
        
        print("ã¾ãŸã€ä»¥ä¸‹ã®å±æ€§ã§çµæœã‚’ç¢ºèªã§ãã¾ã™ï¼š")
        print("   explorer.insights  # ç™ºè¦‹äº‹é …ãƒªã‚¹ãƒˆ")
        print("   explorer.data      # å…ƒãƒ‡ãƒ¼ã‚¿")
        print("   explorer.numeric_cols  # æ•°å€¤åˆ—ãƒªã‚¹ãƒˆ")
    
    def custom_variable_analysis(self, column_name):
        """ç‰¹å®šå¤‰æ•°ã®ã‚«ã‚¹ã‚¿ãƒ åˆ†æ"""
        if column_name not in self.data.columns:
            print(f"åˆ— '{column_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        print(f"\n=== {column_name} ã®è©³ç´°åˆ†æ ===")
        
        data_col = self.data[column_name].dropna()
        
        # åŸºæœ¬çµ±è¨ˆ
        print(f"åŸºæœ¬çµ±è¨ˆ:")
        print(f"  å¹³å‡: {data_col.mean():.3f}")
        print(f"  ä¸­å¤®å€¤: {data_col.median():.3f}")
        print(f"  æ¨™æº–åå·®: {data_col.std():.3f}")
        print(f"  ç¯„å›²: {data_col.min():.3f} ï½ {data_col.max():.3f}")
        
        # åˆ†å¸ƒã®ç‰¹å¾´
        skewness = stats.skew(data_col)
        kurtosis = stats.kurtosis(data_col)
        print(f"\nåˆ†å¸ƒç‰¹æ€§:")
        print(f"  æ­ªåº¦: {skewness:.3f}")
        print(f"  å°–åº¦: {kurtosis:.3f}")
        
        # å¯è¦–åŒ–
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        axes[0,0].hist(data_col, bins=50, alpha=0.7, density=True)
        axes[0,0].set_title(f'{column_name} - åˆ†å¸ƒ')
        
        # ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
        axes[0,1].boxplot(data_col)
        axes[0,1].set_title(f'{column_name} - ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ')
        
        # Q-Qãƒ—ãƒ­ãƒƒãƒˆ
        stats.probplot(data_col, dist="norm", plot=axes[1,0])
        axes[1,0].set_title('æ­£è¦Q-Qãƒ—ãƒ­ãƒƒãƒˆ')
        
        # æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ
        axes[1,1].plot(data_col, alpha=0.7)
        axes[1,1].set_title(f'{column_name} - æ™‚ç³»åˆ—')
        
        plt.tight_layout()
        plt.show()
        
        return data_col
    
    def time_period_analysis(self, start_date, end_date):
        """ç‰¹å®šæœŸé–“ã®åˆ†æ"""
        if self.datetime_col is None:
            print("æ—¥æ™‚åˆ—ãŒãªã„ãŸã‚ã€æœŸé–“åˆ†æã¯ã§ãã¾ã›ã‚“")
            return
        
        # æœŸé–“ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        mask = (self.data[self.datetime_col] >= start_date) & (self.data[self.datetime_col] <= end_date)
        period_data = self.data[mask]
        
        if len(period_data) == 0:
            print("æŒ‡å®šæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        print(f"\n=== {start_date} ï½ {end_date} ã®åˆ†æ ===")
        print(f"æœŸé–“ãƒ‡ãƒ¼ã‚¿æ•°: {len(period_data)}ä»¶")
        
        # åŸºæœ¬çµ±è¨ˆã®æ¯”è¼ƒ
        if len(self.numeric_cols) > 0:
            print("\næœŸé–“çµ±è¨ˆ vs å…¨ä½“çµ±è¨ˆ:")
            
            period_stats = period_data[self.numeric_cols].mean()
            overall_stats = self.data[self.numeric_cols].mean()
            
            comparison = pd.DataFrame({
                'æœŸé–“å¹³å‡': period_stats,
                'å…¨ä½“å¹³å‡': overall_stats,
                'å·®åˆ†': period_stats - overall_stats,
                'å·®åˆ†ç‡(%)': ((period_stats - overall_stats) / overall_stats * 100)
            })
            
            print(comparison.round(3))
        
        return period_data
    
    def generate_comprehensive_insights(self):
        """åŒ…æ‹¬çš„ãªæ´å¯Ÿãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        print("\n" + "=" * 80)
        print("ã€é«˜åº¦åˆ†æ - åŒ…æ‹¬çš„æ´å¯Ÿãƒ¬ãƒãƒ¼ãƒˆã€‘")
        print("=" * 80)
        
        if not self.insights:
            print("ç‰¹ç­†ã™ã¹ãæ´å¯Ÿã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        print("â–  é«˜åº¦åˆ†æã§å¾—ã‚‰ã‚ŒãŸæ´å¯Ÿ:")
        for i, insight in enumerate(self.insights, 1):
            print(f"{i:2d}. {insight}")
        
        print(f"\nâ–  æ´å¯Ÿç·æ•°: {len(self.insights)}ä»¶")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®é›†è¨ˆ
        categories = {
            'å‘¨æœŸæ€§ãƒ»å­£ç¯€æ€§': [i for i in self.insights if any(kw in i for kw in ['å‘¨æœŸ', 'å­£ç¯€', 'FFT'])],
            'å¤‰åŒ–ç‚¹ãƒ»ç•°å¸¸': [i for i in self.insights if any(kw in i for kw in ['å¤‰åŒ–ç‚¹', 'ç•°å¸¸'])],
            'ç›¸é–¢ãƒ»é–¢é€£æ€§': [i for i in self.insights if any(kw in i for kw in ['ç›¸é–¢', 'é–¢é€£'])],
            'ç¨¼åƒãƒ‘ã‚¿ãƒ¼ãƒ³': [i for i in self.insights if any(kw in i for kw in ['ç¨¼åƒ', 'ãƒ”ãƒ¼ã‚¯', 'æ™‚é–“'])],
            'ãƒ—ãƒ­ã‚»ã‚¹ç‰¹æ€§': [i for i in self.insights if any(kw in i for kw in ['ãƒ—ãƒ­ã‚»ã‚¹', 'æˆåˆ†', 'å¤‰å‹•'])]
        }
        
        print("\nâ–  ã‚«ãƒ†ã‚´ãƒªåˆ¥æ´å¯Ÿ:")
        for category, items in categories.items():
            if items:
                print(f"\n{category} ({len(items)}ä»¶):")
                for item in items:
                    print(f"  â€¢ {item}")
        
        return self.insights
    
    def run_advanced_analysis(self):
        """é«˜åº¦åˆ†æã®ä¸€æ‹¬å®Ÿè¡Œ"""
        print("ğŸ”¬ é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æ´å¯Ÿåˆ†æã‚’é–‹å§‹ã—ã¾ã™...")
        
        self.operational_pattern_analysis()
        self.periodicity_detection()
        self.seasonal_decomposition_analysis()
        self.change_point_detection()
        self.cross_correlation_analysis()
        self.process_state_analysis()
        
        # ç·åˆãƒ¬ãƒãƒ¼ãƒˆ
        self.generate_comprehensive_insights()
        
        print("\nâœ… é«˜åº¦åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
        print("\nğŸ’¡ ã•ã‚‰ãªã‚‹æ¢ç´¢ã®ãŸã‚ã« interactive_exploration_guide() ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        
        return self.insights

# ä½¿ç”¨ä¾‹ã¨ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ
def quick_advanced_analysis(data_path, datetime_col=None):
    """ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆç”¨ã®é–¢æ•°"""
    try:
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        data = pd.read_csv(data_path)
        
        # æ—¥æ™‚åˆ—ã®è‡ªå‹•å¤‰æ›
        if datetime_col and datetime_col in data.columns:
            data[datetime_col] = pd.to_datetime(data[datetime_col])
        
        # é«˜åº¦åˆ†æã®å®Ÿè¡Œ
        analyzer = AdvancedFactoryDataInsights(data, datetime_col)
        insights = analyzer.run_advanced_analysis()
        
        return analyzer, insights
        
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None

if __name__ == "__main__":
    print("é«˜åº¦ãƒ‡ãƒ¼ã‚¿æ´å¯Ÿåˆ†æãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨æ–¹æ³•:")
    print("1. ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿: data = pd.read_csv('your_data.csv')")
    print("2. åˆ†æå™¨ã‚’åˆæœŸåŒ–: analyzer = AdvancedFactoryDataInsights(data)")
    print("3. ä¸€æ‹¬åˆ†æå®Ÿè¡Œ: analyzer.run_advanced_analysis()")
    print("4. ã¾ãŸã¯å€‹åˆ¥åˆ†æ: analyzer.operational_pattern_analysis() ãªã©")
    print("\nã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ:")
    print("analyzer, insights = quick_advanced_analysis('your_data.csv', 'datetime_column')") 