# 工場データ包括的探索分析ツール

工場のタグデータ（PV, SV, MV値など）を包括的に分析し、データの特徴的な点を自動的に発見するPythonツールセットです。

## 🎯 目的

- **データ理解の自動化**: 手作業では見つけにくいデータの特徴を自動発見
- **ヒアリング項目の特定**: 現場へのヒアリングが必要な項目を自動抽出
- **予測モデル構築の前準備**: 特徴量エンジニアリングのヒントを提供
- **データ品質の評価**: データの信頼性と分析可能性を評価

## 📋 機能概要

### 基本データ探索分析
- ✅ 基本統計量の詳細分析
- ✅ 欠損値パターンの分析
- ✅ 外れ値の検出と可視化
- ✅ 変数間相関の分析
- ✅ 分布の特性分析
- ✅ データ品質の総合評価

### 高度洞察分析
- 🔬 稼働パターンの時間別分析
- 🔬 周期性・季節性の検出
- 🔬 変化点の自動検出
- 🔬 クロス相関分析（時差相関）
- 🔬 プロセス状態空間分析
- 🔬 異常運転状態の検出

## 🚀 クイックスタート

### 1. 環境セットアップ

```bash
# 必要なライブラリのインストール
pip install -r requirements.txt
```

### 2. データファイルの準備

CSVファイルでデータを準備してください。例：

```
timestamp,temp_pv,temp_sv,temp_mv,pressure_pv,moisture_target
2024-01-01 00:00:00,85.2,85.0,45.3,2.1,12.5
2024-01-01 00:05:00,85.1,85.0,45.1,2.1,12.3
...
```

### 3. 分析実行

#### 方法1: メインスクリプトで一括実行（推奨）

```bash
python run_data_exploration.py
```

または、ファイルパスを指定：

```bash
python run_data_exploration.py your_data.csv timestamp
```

#### 方法2: 個別実行

```python
# 基本分析のみ
from data_exploration import FactoryDataExplorer

explorer = FactoryDataExplorer("your_data.csv")
findings = explorer.run_comprehensive_analysis()
```

```python
# 高度分析のみ
import pandas as pd
from advanced_data_insights import AdvancedFactoryDataInsights

data = pd.read_csv("your_data.csv")
analyzer = AdvancedFactoryDataInsights(data, datetime_col="timestamp")
insights = analyzer.run_advanced_analysis()
```

## 📊 分析結果の見方

### 出力される情報

1. **基本データ情報**
   - データ形状、メモリ使用量
   - 列ごとのデータ型、欠損率、ユニーク数

2. **統計的サマリー**
   - 基本統計量（平均、標準偏差、分位数）
   - 歪度、尖度、変動係数
   - 特異な分布パターンの検出

3. **データ品質評価**
   - 欠損値パターン
   - 重複データ
   - 外れ値の詳細分析
   - 品質スコア（0-100点）

4. **時系列特性**
   - サンプリング間隔の分析
   - 稼働パターン（時間別、曜日別）
   - 周期性・季節性の検出

5. **変数間関係**
   - 相関行列とヒートマップ
   - 高相関ペアの特定
   - 時差相関（クロス相関）

6. **発見事項レポート**
   - 重要度別の問題分類
   - ヒアリング推奨項目
   - 次のステップの提案

### 重要度の分類

- 🔴 **高優先度**: 外れ値、異常、欠損、品質問題
- 🟡 **中優先度**: 相関、周期、季節性、トレンド
- 🟢 **低優先度**: 稼働パターン、クラスタリング
- ⚪ **その他**: 一般的な特徴

## 🔧 カスタマイズ

### ファイル構成の変更

`run_data_exploration.py` の設定部分を編集：

```python
# データファイルのパス
data_path = "your_data.csv"  # ここを変更

# 日時列名（自動検出も可能）
datetime_column = "timestamp"  # 日時列名を指定
```

### 個別分析の実行

```python
# 特定の変数を詳細分析
explorer.custom_variable_analysis('temperature_pv')

# 特定期間の分析
explorer.time_period_analysis('2024-01-01', '2024-01-31')

# 稼働パターンのみ分析
analyzer.operational_pattern_analysis()

# 周期性検出のみ
analyzer.periodicity_detection()
```

## 📈 分析結果の活用方法

### 1. データ品質改善
- 欠損値の発生原因を現場にヒアリング
- 外れ値の妥当性確認
- 計測器の校正状況確認

### 2. 特徴量エンジニアリング
- 高相関変数から派生変数を作成
- 周期性を活用した時間特徴量
- 移動平均等の平滑化特徴量

### 3. 予測モデル設計
- 30分遅れ特徴量の効果検証
- 時系列分割による適切な検証設計
- 重要変数の優先的な利用

### 4. 運用改善
- 稼働パターンの最適化
- 異常検知ルールの設定
- データ収集プロセスの見直し

## 🔍 よくある分析パターン

### パターン1: 高い相関が発見された場合
```
発見: "temp_pv-temp_sv: 高相関 (r=0.95)"
→ ヒアリング: 制御ロジックの詳細
→ 対応: PV-SV偏差を新特徴量として活用
```

### パターン2: 周期性が検出された場合
```
発見: "pressure_pv: 主要周期 = [24, 168]ポイント"
→ ヒアリング: 日次・週次の運転サイクル
→ 対応: 時間特徴量（時間、曜日）を追加
```

### パターン3: 外れ値が多数検出された場合
```
発見: "moisture_pv: 多数の外れ値 (5.2%)"
→ ヒアリング: 計測器の異常、メンテナンス履歴
→ 対応: 外れ値除去ルールの策定
```

## 🚨 注意事項

### データ要件
- **最小データ数**: 100行以上推奨（1000行以上で高精度）
- **ファイル形式**: CSV（UTF-8エンコーディング）
- **日時形式**: ISO形式（YYYY-MM-DD HH:MM:SS）推奨

### パフォーマンス
- **大規模データ**: 100万行以上では処理時間が長くなる可能性
- **メモリ使用量**: データサイズの3-5倍程度のメモリが必要
- **可視化**: グラフ生成で時間がかかる場合があります

### 制限事項
- 非数値データの分析は限定的
- 極度に不規則な時系列では一部分析が不正確な場合
- 複雑な非線形関係は検出できない場合

## 💡 トラブルシューティング

### よくあるエラーと解決方法

**エラー1**: `FileNotFoundError`
```
解決: ファイルパスが正しいか確認
- 現在のディレクトリにファイルがあるか
- ファイル名のスペルミス
```

**エラー2**: `ValueError: could not convert string to float`
```
解決: データ形式の確認
- 数値列に文字列が混入していないか
- 欠損値の表現（NaN, NULL, 空文字）
```

**エラー3**: メモリ不足
```
解決: データサイズの調整
- サンプリングによるデータ削減
- 不要な列の除去
- チャンクごとの処理
```

## 📞 サポート

問題が発生した場合は、以下の情報とともにお問い合わせください：

1. エラーメッセージの全文
2. データファイルの基本情報（行数、列数、サイズ）
3. 実行環境（Python バージョン、OS）
4. 実行したコマンドまたはコード

## 🔄 更新履歴

- **v1.0.0**: 初期リリース
  - 基本データ探索機能
  - 高度洞察分析機能
  - 統合レポート機能 